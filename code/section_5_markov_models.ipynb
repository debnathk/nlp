{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCZRXavbMLbE"
      },
      "source": [
        "# Section 5 - Markov Models"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic definitions\n",
        "\n",
        ">**Markov property**:\n",
        "- The probability of a word occurring depends only on the previous word or a fixed number of preceding words, and not on the earlier words.\n",
        "\n",
        ">**State transition matrix (denoted as `A`)**:\n",
        "- A 2D matrix of the probabilities of transitioning from one state to another.\n",
        "\n",
        ">**Initial state distribution (denoted as `π`)**:\n",
        "- The probability distribution over the possible starting states.\n",
        "\n",
        ">**Priors**:\n",
        "- Probability distribution of the classes."
      ],
      "metadata": {
        "id": "7iMluAgKMuJ8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hshcKBPqMLbG"
      },
      "source": [
        "## Case Study - Building a Text Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCUs__THMLbG",
        "outputId": "21f0baa7-c0a1-4d83-a9a8-138f34529ca9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-15 04:42:46--  https://raw.githubusercontent.com/lazyprogrammer/machine_learning_examples/master/hmm_class/edgar_allan_poe.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 26622 (26K) [text/plain]\n",
            "Saving to: ‘edgar_allan_poe.txt’\n",
            "\n",
            "\redgar_allan_poe.txt   0%[                    ]       0  --.-KB/s               \redgar_allan_poe.txt 100%[===================>]  26.00K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-06-15 04:42:46 (8.66 MB/s) - ‘edgar_allan_poe.txt’ saved [26622/26622]\n",
            "\n",
            "--2024-06-15 04:42:46--  https://raw.githubusercontent.com/lazyprogrammer/machine_learning_examples/master/hmm_class/robert_frost.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 56286 (55K) [text/plain]\n",
            "Saving to: ‘robert_frost.txt’\n",
            "\n",
            "robert_frost.txt    100%[===================>]  54.97K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-06-15 04:42:47 (4.15 MB/s) - ‘robert_frost.txt’ saved [56286/56286]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download datasets\n",
        "!wget -nc https://raw.githubusercontent.com/lazyprogrammer/machine_learning_examples/master/hmm_class/edgar_allan_poe.txt\n",
        "!wget -nc https://raw.githubusercontent.com/lazyprogrammer/machine_learning_examples/master/hmm_class/robert_frost.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "78EAITbyNNGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_files = [\n",
        "    'edgar_allan_poe.txt',\n",
        "    'robert_frost.txt'\n",
        "]"
      ],
      "metadata": {
        "id": "wWj2sC1fNN9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head edgar_allan_poe.txt"
      ],
      "metadata": {
        "id": "EKCoGYgrNcdy",
        "outputId": "59166046-298e-4719-fb4a-47a27a78a1c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LO! Death hath rear'd himself a throne\n",
            "In a strange city, all alone,\n",
            "Far down within the dim west\n",
            "Where the good, and the bad, and the worst, and the best,\n",
            "Have gone to their eternal rest.\n",
            " \n",
            "There shrines, and palaces, and towers\n",
            "Are not like any thing of ours\n",
            "Oh no! O no! ours never loom\n",
            "To heaven with that ungodly gloom!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head robert_frost.txt"
      ],
      "metadata": {
        "id": "eC8ZcSyhNehS",
        "outputId": "f0d2ae17-d528-4376-fa89-c6b7e61588cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Two roads diverged in a yellow wood,\n",
            "And sorry I could not travel both\n",
            "And be one traveler, long I stood\n",
            "And looked down one as far as I could\n",
            "To where it bent in the undergrowth; \n",
            "\n",
            "Then took the other, as just as fair,\n",
            "And having perhaps the better claim\n",
            "Because it was grassy and wanted wear,\n",
            "Though as for that the passing there\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# collect data into lists\n",
        "input_texts = []\n",
        "labels = []\n",
        "\n",
        "for label, f in enumerate(input_files):\n",
        "  print(f\"{f} corresponds to label {label}\")\n",
        "\n",
        "  for line in open(f):\n",
        "    line = line.rstrip().lower()\n",
        "    if line:\n",
        "      # remove punctuations\n",
        "      line = line.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "      input_texts.append(line)\n",
        "      labels.append(label)"
      ],
      "metadata": {
        "id": "krB43KLPNhP5",
        "outputId": "91b138c6-3111-48e0-e381-3c58fea554f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "edgar_allan_poe.txt corresponds to label 0\n",
            "robert_frost.txt corresponds to label 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_text, test_text, y_train, y_test = train_test_split(input_texts, labels)"
      ],
      "metadata": {
        "id": "aF0ZLTeENkdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(y_train), len(y_test)"
      ],
      "metadata": {
        "id": "XGXi8GelNnEf",
        "outputId": "ef81256b-87ff-415e-88ae-23b656ef35d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1615, 539)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_text[:5], y_train[:5]"
      ],
      "metadata": {
        "id": "jeEqrgWqNpco",
        "outputId": "30aa164c-4af4-4bfd-fa8b-85b87e610ad5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['you mean oh for some miss',\n",
              "  'a passionate light such for his spirit was fit',\n",
              "  'let my future radiant shine',\n",
              "  'and then becoming reconciled',\n",
              "  'science true daughter of old time thou art'],\n",
              " [1, 0, 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 1\n",
        "word2idx = {'<unk>':0}"
      ],
      "metadata": {
        "id": "Aowl5_4cNrtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# populate word2idx\n",
        "for text in train_text:\n",
        "  tokens = text.split()\n",
        "  for token in tokens:\n",
        "    if token not in word2idx:\n",
        "      word2idx[token] = idx\n",
        "      idx += 1"
      ],
      "metadata": {
        "id": "W1Ob4feoNxmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2idx"
      ],
      "metadata": {
        "id": "XgtgnTxuN0Y5",
        "outputId": "a7b2691e-28dc-4acb-90a0-2fa6682c65ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<unk>': 0,\n",
              " 'you': 1,\n",
              " 'mean': 2,\n",
              " 'oh': 3,\n",
              " 'for': 4,\n",
              " 'some': 5,\n",
              " 'miss': 6,\n",
              " 'a': 7,\n",
              " 'passionate': 8,\n",
              " 'light': 9,\n",
              " 'such': 10,\n",
              " 'his': 11,\n",
              " 'spirit': 12,\n",
              " 'was': 13,\n",
              " 'fit': 14,\n",
              " 'let': 15,\n",
              " 'my': 16,\n",
              " 'future': 17,\n",
              " 'radiant': 18,\n",
              " 'shine': 19,\n",
              " 'and': 20,\n",
              " 'then': 21,\n",
              " 'becoming': 22,\n",
              " 'reconciled': 23,\n",
              " 'science': 24,\n",
              " 'true': 25,\n",
              " 'daughter': 26,\n",
              " 'of': 27,\n",
              " 'old': 28,\n",
              " 'time': 29,\n",
              " 'thou': 30,\n",
              " 'art': 31,\n",
              " 'perhaps': 32,\n",
              " 'it': 33,\n",
              " 'may': 34,\n",
              " 'be': 35,\n",
              " 'that': 36,\n",
              " 'mind': 37,\n",
              " 'is': 38,\n",
              " 'wrought': 39,\n",
              " 'i': 40,\n",
              " 'say': 41,\n",
              " 'on': 42,\n",
              " 'consideration': 43,\n",
              " 'know': 44,\n",
              " 'one': 45,\n",
              " 'didnt': 46,\n",
              " 'thrive': 47,\n",
              " 'the': 48,\n",
              " 'west': 49,\n",
              " 'getting': 50,\n",
              " 'out': 51,\n",
              " 'gold': 52,\n",
              " 'save': 53,\n",
              " 'but': 54,\n",
              " 'soul': 55,\n",
              " 'in': 56,\n",
              " 'thine': 57,\n",
              " 'uplifted': 58,\n",
              " 'eyes': 59,\n",
              " 'smell': 60,\n",
              " 'wet': 61,\n",
              " 'feathers': 62,\n",
              " 'heat': 63,\n",
              " 'supposed': 64,\n",
              " 'to': 65,\n",
              " 'mad': 66,\n",
              " 'resurrection': 67,\n",
              " 'deepburied': 68,\n",
              " 'faith': 69,\n",
              " 'will': 70,\n",
              " 'leave': 71,\n",
              " 'their': 72,\n",
              " 'tatters': 73,\n",
              " 'hung': 74,\n",
              " 'barb': 75,\n",
              " 'thorn': 76,\n",
              " 'skies': 77,\n",
              " 'they': 78,\n",
              " 'were': 79,\n",
              " 'ashen': 80,\n",
              " 'sober': 81,\n",
              " 'hold': 82,\n",
              " 'door': 83,\n",
              " 'bones': 84,\n",
              " 'try': 85,\n",
              " 'shall': 86,\n",
              " 'do': 87,\n",
              " 'reverence': 88,\n",
              " 'looked': 89,\n",
              " 'down': 90,\n",
              " 'as': 91,\n",
              " 'far': 92,\n",
              " 'could': 93,\n",
              " 'never': 94,\n",
              " 'saw': 95,\n",
              " 'man': 96,\n",
              " 'family': 97,\n",
              " 'troubles': 98,\n",
              " 'builder': 99,\n",
              " 'building': 100,\n",
              " 'little': 101,\n",
              " 'house': 102,\n",
              " 'stamped': 103,\n",
              " 'said': 104,\n",
              " 'things': 105,\n",
              " 'himself': 106,\n",
              " 'why': 107,\n",
              " 'not': 108,\n",
              " 'take': 109,\n",
              " 'two': 110,\n",
              " 'or': 111,\n",
              " 'three': 112,\n",
              " 'john': 113,\n",
              " 'too': 114,\n",
              " 'have': 115,\n",
              " 'grandchildren': 116,\n",
              " 'went': 117,\n",
              " 'sleep': 118,\n",
              " 'before': 119,\n",
              " 'bed': 120,\n",
              " 'cant': 121,\n",
              " 'pretend': 122,\n",
              " 'tell': 123,\n",
              " 'way': 124,\n",
              " 'its': 125,\n",
              " 'done': 126,\n",
              " 'dont': 127,\n",
              " 'believe': 128,\n",
              " 'me': 129,\n",
              " 'when': 130,\n",
              " 'he': 131,\n",
              " 'made': 132,\n",
              " 'at': 133,\n",
              " 'tutelar': 134,\n",
              " 'shrine': 135,\n",
              " 'truth': 136,\n",
              " 'suppose': 137,\n",
              " 'had': 138,\n",
              " 'come': 139,\n",
              " 'up': 140,\n",
              " 'toward': 141,\n",
              " 'heaven': 142,\n",
              " 'there': 143,\n",
              " 'against': 144,\n",
              " 'blue': 145,\n",
              " 'libation': 146,\n",
              " 'tyrannys': 147,\n",
              " 'blood': 148,\n",
              " 'them': 149,\n",
              " 'get': 150,\n",
              " 'through': 151,\n",
              " 'though': 152,\n",
              " 'hes': 153,\n",
              " 'nothing': 154,\n",
              " 'listen': 155,\n",
              " 'lean': 156,\n",
              " 'like': 157,\n",
              " 'this': 158,\n",
              " 'everybody': 159,\n",
              " 'took': 160,\n",
              " 'proof': 161,\n",
              " 'moon': 162,\n",
              " 'stars': 163,\n",
              " 'with': 164,\n",
              " 'gourd': 165,\n",
              " 'grape': 166,\n",
              " 'luxuriant': 167,\n",
              " 'grew': 168,\n",
              " 'fair': 169,\n",
              " 'isle': 170,\n",
              " 'from': 171,\n",
              " 'fairest': 172,\n",
              " 'all': 173,\n",
              " 'flowers': 174,\n",
              " 'sink': 175,\n",
              " 'under': 176,\n",
              " 'being': 177,\n",
              " 'wife': 178,\n",
              " 'by': 179,\n",
              " 'good': 180,\n",
              " 'angels': 181,\n",
              " 'tenanted': 182,\n",
              " 'guess': 183,\n",
              " 'estelle': 184,\n",
              " 'filled': 185,\n",
              " 'purse': 186,\n",
              " 'slightly': 187,\n",
              " 'sinking': 188,\n",
              " 'dull': 189,\n",
              " 'tide': 190,\n",
              " 'content': 191,\n",
              " 'budinspecting': 192,\n",
              " 'presume': 193,\n",
              " 'beauty': 194,\n",
              " 'our': 195,\n",
              " 'god': 196,\n",
              " 'those': 197,\n",
              " 'alone': 198,\n",
              " 'us': 199,\n",
              " 'tremulous': 200,\n",
              " 'hast': 201,\n",
              " 'dragged': 202,\n",
              " 'diana': 203,\n",
              " 'her': 204,\n",
              " 'car': 205,\n",
              " 'wonder': 206,\n",
              " 'where': 207,\n",
              " 'cold': 208,\n",
              " 'coming': 209,\n",
              " 'we': 210,\n",
              " 'can': 211,\n",
              " 'just': 212,\n",
              " 'see': 213,\n",
              " 'infant': 214,\n",
              " 'astride': 215,\n",
              " 'best': 216,\n",
              " 'right': 217,\n",
              " 'heard': 218,\n",
              " 'place': 219,\n",
              " 'dead': 220,\n",
              " 'race': 221,\n",
              " 'great': 222,\n",
              " 'auk': 223,\n",
              " 'trapper': 224,\n",
              " 'looking': 225,\n",
              " 'if': 226,\n",
              " 'must': 227,\n",
              " 'sunshine': 228,\n",
              " 'so': 229,\n",
              " 'she': 230,\n",
              " 'here': 231,\n",
              " 'once': 232,\n",
              " 'an': 233,\n",
              " 'alley': 234,\n",
              " 'titanic': 235,\n",
              " 'luminary': 236,\n",
              " 'clock': 237,\n",
              " 'sky': 238,\n",
              " 'within': 239,\n",
              " 'dim': 240,\n",
              " 'been': 241,\n",
              " 'master': 242,\n",
              " 'grange': 243,\n",
              " 'another': 244,\n",
              " 'want': 245,\n",
              " 'hear': 246,\n",
              " 'talk': 247,\n",
              " 'ah': 248,\n",
              " 'safely': 249,\n",
              " 'trust': 250,\n",
              " 'gleaming': 251,\n",
              " 'thy': 252,\n",
              " 'grace': 253,\n",
              " 'did': 254,\n",
              " 'guide': 255,\n",
              " 'thee': 256,\n",
              " 'mother': 257,\n",
              " 'only': 258,\n",
              " 'fault': 259,\n",
              " 'husband': 260,\n",
              " 'found': 261,\n",
              " 'ecstasies': 262,\n",
              " 'above': 263,\n",
              " 'stained': 264,\n",
              " 'vegetation': 265,\n",
              " 'consent': 266,\n",
              " 'give': 267,\n",
              " 'sign': 268,\n",
              " 'make': 269,\n",
              " 'worth': 270,\n",
              " 'lifes': 271,\n",
              " 'while': 272,\n",
              " 'wake': 273,\n",
              " 'sport': 274,\n",
              " 'whose': 275,\n",
              " 'woods': 276,\n",
              " 'these': 277,\n",
              " 'are': 278,\n",
              " 'think': 279,\n",
              " 'tree': 280,\n",
              " 'beside': 281,\n",
              " 'wall': 282,\n",
              " 'stands': 283,\n",
              " 'bare': 284,\n",
              " 'youd': 285,\n",
              " 'find': 286,\n",
              " 'fountain': 287,\n",
              " 'empty': 288,\n",
              " 'hath': 289,\n",
              " 'ever': 290,\n",
              " 'told': 291,\n",
              " 'thought': 292,\n",
              " 'fine': 293,\n",
              " 'fibrils': 294,\n",
              " 'life': 295,\n",
              " 'noted': 296,\n",
              " 'lake': 297,\n",
              " 'auber': 298,\n",
              " 'experts': 299,\n",
              " 'deep': 300,\n",
              " 'mountain': 301,\n",
              " 'son': 302,\n",
              " 'headboard': 303,\n",
              " 'mothers': 304,\n",
              " 'pushed': 305,\n",
              " 'raining': 306,\n",
              " 'doubted': 307,\n",
              " 'should': 308,\n",
              " 'back': 309,\n",
              " 'quickening': 310,\n",
              " 'spell': 311,\n",
              " 'doth': 312,\n",
              " 'oer': 313,\n",
              " 'pass': 314,\n",
              " 'plunged': 315,\n",
              " 'tyrant': 316,\n",
              " 'steel': 317,\n",
              " 'sincere': 318,\n",
              " 'reply': 319,\n",
              " 'ice': 320,\n",
              " 'high': 321,\n",
              " 'tone': 322,\n",
              " 'which': 323,\n",
              " 'striven': 324,\n",
              " 'theirs': 325,\n",
              " 'interlock': 326,\n",
              " 'except': 327,\n",
              " 'always': 328,\n",
              " 'johnjoe': 329,\n",
              " 'fly': 330,\n",
              " 'what': 331,\n",
              " 'either': 332,\n",
              " 'cloud': 333,\n",
              " 'smoke': 334,\n",
              " 'im': 335,\n",
              " 'size': 336,\n",
              " 'stairs': 337,\n",
              " 'night': 338,\n",
              " 'stand': 339,\n",
              " 'perplexed': 340,\n",
              " 'who': 341,\n",
              " 'wouldst': 342,\n",
              " 'him': 343,\n",
              " 'wandering': 344,\n",
              " 'softmurmured': 345,\n",
              " 'words': 346,\n",
              " 'fulfilled': 347,\n",
              " 'rivers': 348,\n",
              " 'glide': 349,\n",
              " 'chisel': 350,\n",
              " 'work': 351,\n",
              " 'enormous': 352,\n",
              " 'glacier': 353,\n",
              " 'miles': 354,\n",
              " 'go': 355,\n",
              " 'kitchen': 356,\n",
              " 'dark': 357,\n",
              " 'own': 358,\n",
              " 'legended': 359,\n",
              " 'tomb': 360,\n",
              " 'conies': 361,\n",
              " 'now': 362,\n",
              " 'sun': 363,\n",
              " 'romp': 364,\n",
              " 'daylight': 365,\n",
              " 'birth': 366,\n",
              " 'gone': 367,\n",
              " 'course': 368,\n",
              " 'stay': 369,\n",
              " 'henceforth': 370,\n",
              " 'flowerenameled': 371,\n",
              " 'shore': 372,\n",
              " 'alas': 373,\n",
              " 'cannot': 374,\n",
              " 'feel': 375,\n",
              " 'tis': 376,\n",
              " 'feeling': 377,\n",
              " 'hall': 378,\n",
              " 'novelty': 379,\n",
              " 'toffile': 380,\n",
              " 'agreed': 381,\n",
              " 'sure': 382,\n",
              " 'enough': 383,\n",
              " 'tent': 384,\n",
              " 'grove': 385,\n",
              " 'orchard': 386,\n",
              " 'ye': 387,\n",
              " 'avengers': 388,\n",
              " 'libertys': 389,\n",
              " 'wrongs': 390,\n",
              " 'happens': 391,\n",
              " 'broken': 392,\n",
              " 'davis': 393,\n",
              " 'youth': 394,\n",
              " 'known': 395,\n",
              " 'whom': 396,\n",
              " 'earth': 397,\n",
              " 'transforming': 398,\n",
              " 'charms': 399,\n",
              " 'please': 400,\n",
              " 'no': 401,\n",
              " 'more': 402,\n",
              " 'paddle': 403,\n",
              " 'blade': 404,\n",
              " 'loved': 405,\n",
              " 'object': 406,\n",
              " 'tear': 407,\n",
              " 'lid': 408,\n",
              " 'makes': 409,\n",
              " 'head': 410,\n",
              " 'spin': 411,\n",
              " 'driven': 412,\n",
              " 'rain': 413,\n",
              " 'swollen': 414,\n",
              " 'wrong': 415,\n",
              " 'passed': 416,\n",
              " 'end': 417,\n",
              " 'vista': 418,\n",
              " 'has': 419,\n",
              " 'seen': 420,\n",
              " 'tears': 421,\n",
              " 'dry': 422,\n",
              " 'smiled': 423,\n",
              " 'died': 424,\n",
              " 'parterre': 425,\n",
              " 'enchanted': 426,\n",
              " 'doubt': 427,\n",
              " 'grown': 428,\n",
              " 'around': 429,\n",
              " 'sybilic': 430,\n",
              " 'splendor': 431,\n",
              " 'beaming': 432,\n",
              " 'office': 433,\n",
              " 'illumine': 434,\n",
              " 'enkindle': 435,\n",
              " 'nothings': 436,\n",
              " 'pays': 437,\n",
              " 'rolls': 438,\n",
              " 'ether': 439,\n",
              " 'sighs': 440,\n",
              " 'name': 441,\n",
              " 'am': 442,\n",
              " 'werent': 443,\n",
              " 'wild': 444,\n",
              " 'geese': 445,\n",
              " 'storm': 446,\n",
              " 'knew': 447,\n",
              " 'reason': 448,\n",
              " 'greatly': 449,\n",
              " 'afraid': 450,\n",
              " 'fire': 451,\n",
              " 'hot': 452,\n",
              " 'first': 453,\n",
              " 'buy': 454,\n",
              " 'half': 455,\n",
              " 'ear': 456,\n",
              " 'pianos': 457,\n",
              " 'vigor': 458,\n",
              " 'twothousandmile': 459,\n",
              " 'coast': 460,\n",
              " 'extravagance': 461,\n",
              " 'young': 462,\n",
              " 'love': 463,\n",
              " 'bout': 464,\n",
              " 'long': 465,\n",
              " 'home': 466,\n",
              " 'headless': 467,\n",
              " 'aftermath': 468,\n",
              " 'well—i—be—': 469,\n",
              " 'than': 470,\n",
              " 'brought': 471,\n",
              " 'into': 472,\n",
              " 'boring': 473,\n",
              " 'climbing': 474,\n",
              " 'need': 475,\n",
              " 'endless': 476,\n",
              " 'talktalk': 477,\n",
              " 'weak': 478,\n",
              " 'lines': 479,\n",
              " 'written': 480,\n",
              " 'groan': 481,\n",
              " 'roll': 482,\n",
              " 'mount': 483,\n",
              " 'yaanek': 484,\n",
              " 'anything': 485,\n",
              " 'warn': 486,\n",
              " 'sometimes': 487,\n",
              " 'came': 488,\n",
              " 'arms': 489,\n",
              " 'outspread': 490,\n",
              " 'boys': 491,\n",
              " 'bad': 492,\n",
              " 'hunters': 493,\n",
              " 'board': 494,\n",
              " 'laid': 495,\n",
              " 'walk': 496,\n",
              " 'dryshod': 497,\n",
              " 'steered': 498,\n",
              " 'really': 499,\n",
              " 'straight': 500,\n",
              " 'away': 501,\n",
              " 'ask': 502,\n",
              " 'better': 503,\n",
              " 'virtue': 504,\n",
              " 'humanity': 505,\n",
              " 'poor': 506,\n",
              " 'dear': 507,\n",
              " 'granny': 508,\n",
              " 'red': 509,\n",
              " 'levin': 510,\n",
              " 'listened': 511,\n",
              " 'till': 512,\n",
              " 'almost': 513,\n",
              " 'climbed': 514,\n",
              " 'else': 515,\n",
              " 'remoteness': 516,\n",
              " 'defied': 517,\n",
              " 'cane': 518,\n",
              " 'knock': 519,\n",
              " 'queenly': 520,\n",
              " 'lily': 521,\n",
              " 'adown': 522,\n",
              " 'dale': 523,\n",
              " 'nails': 524,\n",
              " 'nail': 525,\n",
              " 'shut': 526,\n",
              " 'defeat': 527,\n",
              " 'cried': 528,\n",
              " 'surely': 529,\n",
              " 'october': 530,\n",
              " 'absence': 531,\n",
              " 'money': 532,\n",
              " 'suddenly': 533,\n",
              " 'transfixed': 534,\n",
              " 'slopes': 535,\n",
              " 'erect': 536,\n",
              " 'somewhere': 537,\n",
              " 'ages': 538,\n",
              " 'hence': 539,\n",
              " 'sat': 540,\n",
              " 'floor': 541,\n",
              " 'shouted': 542,\n",
              " 'bird': 543,\n",
              " 'alight': 544,\n",
              " 'tumultuous': 545,\n",
              " 'sea': 546,\n",
              " 'hell': 547,\n",
              " 'knees': 548,\n",
              " 'unless': 549,\n",
              " 'hellforleather': 550,\n",
              " 'twas': 551,\n",
              " 'sound': 552,\n",
              " 'silence': 553,\n",
              " 't': 554,\n",
              " 'awake': 555,\n",
              " 'symbol': 556,\n",
              " 'token': 557,\n",
              " 'your': 558,\n",
              " 'going': 559,\n",
              " 'swish': 560,\n",
              " 'grass': 561,\n",
              " 'others': 562,\n",
              " 'among': 563,\n",
              " 'raspberries': 564,\n",
              " 'hew': 565,\n",
              " 'shape': 566,\n",
              " 'stark': 567,\n",
              " 'drew': 568,\n",
              " 'passport': 569,\n",
              " 'hens': 570,\n",
              " 'cows': 571,\n",
              " 'pigs': 572,\n",
              " 'different': 573,\n",
              " 'least': 574,\n",
              " 'fancied': 575,\n",
              " 'six': 576,\n",
              " 'oclock': 577,\n",
              " 'plumes': 578,\n",
              " 'trailed': 579,\n",
              " 'dust': 580,\n",
              " 'spilled': 581,\n",
              " 'near': 582,\n",
              " 'window': 583,\n",
              " 'ought': 584,\n",
              " 'yourself': 585,\n",
              " 'meet': 586,\n",
              " 'elsewhere': 587,\n",
              " 'lupine': 588,\n",
              " 'living': 589,\n",
              " 'sand': 590,\n",
              " 'drouth': 591,\n",
              " 'turned': 592,\n",
              " 'repented': 593,\n",
              " 'certain': 594,\n",
              " 'coolness': 595,\n",
              " 'lost': 596,\n",
              " 'tongue': 597,\n",
              " 'yet': 598,\n",
              " 'hour': 599,\n",
              " 'whatever': 600,\n",
              " 'cost': 601,\n",
              " 'apiece': 602,\n",
              " 'pound': 603,\n",
              " 'since': 604,\n",
              " 'put': 605,\n",
              " 'foot': 606,\n",
              " 'without': 607,\n",
              " 'avail': 608,\n",
              " 'begin': 609,\n",
              " 'over': 610,\n",
              " 'shed': 611,\n",
              " 'stop': 612,\n",
              " 'held': 613,\n",
              " 'leaves': 614,\n",
              " 'crisped': 615,\n",
              " 'sere': 616,\n",
              " 'witchs': 617,\n",
              " 'motto': 618,\n",
              " 'anyway': 619,\n",
              " 'struck': 620,\n",
              " 'en': 621,\n",
              " 'masse': 622,\n",
              " 'simply': 623,\n",
              " 'lay': 624,\n",
              " 'someone': 625,\n",
              " 'walked': 626,\n",
              " 'sunday': 627,\n",
              " 'after': 628,\n",
              " 'church': 629,\n",
              " 'write': 630,\n",
              " 'speak': 631,\n",
              " 'castles': 632,\n",
              " 'used': 633,\n",
              " 'build': 634,\n",
              " 'air': 635,\n",
              " 'replied': 636,\n",
              " 'dreaming': 637,\n",
              " 'call': 638,\n",
              " 'nausicaa': 639,\n",
              " 'timber': 640,\n",
              " 'how': 641,\n",
              " 'neighbour': 642,\n",
              " 'someones': 643,\n",
              " 'road': 644,\n",
              " 'town': 645,\n",
              " 'threw': 646,\n",
              " 'wide': 647,\n",
              " 'enter': 648,\n",
              " 'owing': 649,\n",
              " 'lyre': 650,\n",
              " 'nights': 651,\n",
              " 'year': 652,\n",
              " 'upturnd': 653,\n",
              " 'sorrow': 654,\n",
              " 'hand': 655,\n",
              " 'off': 656,\n",
              " 'brittle': 657,\n",
              " 'last': 658,\n",
              " 'hesperides': 659,\n",
              " 'books': 660,\n",
              " 'thrown': 661,\n",
              " 'irreverently': 662,\n",
              " 'about': 663,\n",
              " 'ridgely': 664,\n",
              " 'torrence': 665,\n",
              " 'smoothlaid': 666,\n",
              " 'thatch': 667,\n",
              " 'heavy': 668,\n",
              " 'dew': 669,\n",
              " 'whether': 670,\n",
              " 'bowed': 671,\n",
              " 'natural': 672,\n",
              " 'law': 673,\n",
              " 'shatter': 674,\n",
              " 'inward': 675,\n",
              " 'unswept': 676,\n",
              " 'floors': 677,\n",
              " 'choice': 678,\n",
              " 'talkedof': 679,\n",
              " 'mystery': 680,\n",
              " 'hope': 681,\n",
              " 'sees': 682,\n",
              " 'chimney': 683,\n",
              " 'would': 684,\n",
              " 'serve': 685,\n",
              " 'remind': 686,\n",
              " 'worse': 687,\n",
              " 'bent': 688,\n",
              " 'undergrowth': 689,\n",
              " 'fulllength': 690,\n",
              " 'set': 691,\n",
              " 'sweet': 692,\n",
              " 'ere': 693,\n",
              " 'kept': 694,\n",
              " 'hidden': 695,\n",
              " 'instep': 696,\n",
              " 'arch': 697,\n",
              " 'politician': 698,\n",
              " 'odd': 699,\n",
              " 'seasons': 700,\n",
              " 'got': 701,\n",
              " 'day': 702,\n",
              " 'crystal': 703,\n",
              " 'palace': 704,\n",
              " 'london': 705,\n",
              " 'imported': 706,\n",
              " 'obscured': 707,\n",
              " 'lift': 708,\n",
              " 'face': 709,\n",
              " 'word': 710,\n",
              " 'weather': 711,\n",
              " 'other': 712,\n",
              " 'sounds': 713,\n",
              " 'sweep': 714,\n",
              " 'remembering': 715,\n",
              " 'didst': 716,\n",
              " 'remained': 717,\n",
              " 'seraphic': 718,\n",
              " 'glancing': 719,\n",
              " 'eat': 720,\n",
              " 'barrel': 721,\n",
              " 'ground': 722,\n",
              " 'gushing': 723,\n",
              " 'strange': 724,\n",
              " 'well': 725,\n",
              " 'dank': 726,\n",
              " 'tarn': 727,\n",
              " 'hinder': 728,\n",
              " 'flowing': 729,\n",
              " 'dangle': 730,\n",
              " 'feet': 731,\n",
              " 'raspberry': 732,\n",
              " 'vines': 733,\n",
              " 'live': 734,\n",
              " 'fell': 735,\n",
              " 'lantern': 736,\n",
              " 'rattle': 737,\n",
              " 'flying': 738,\n",
              " 'silent': 739,\n",
              " 'flight': 740,\n",
              " 'moment': 741,\n",
              " 'stood': 742,\n",
              " 'balancing': 743,\n",
              " 'emotion': 744,\n",
              " 'matter': 745,\n",
              " 'several': 746,\n",
              " 'youre': 747,\n",
              " 'left': 748,\n",
              " 'named': 749,\n",
              " 'voice': 750,\n",
              " 'mute': 751,\n",
              " 'stove': 752,\n",
              " 'stillgoing': 753,\n",
              " 'every': 754,\n",
              " 'joints': 755,\n",
              " 'myself': 756,\n",
              " 'thinks': 757,\n",
              " 'footstep': 758,\n",
              " 'stirred': 759,\n",
              " 'hated': 760,\n",
              " 'world': 761,\n",
              " 'slept': 762,\n",
              " 'lie': 763,\n",
              " 'stones': 764,\n",
              " 'bushes': 765,\n",
              " 'unretrieved': 766,\n",
              " 'farmhouse': 767,\n",
              " 'roads': 768,\n",
              " 'diverged': 769,\n",
              " 'yellow': 770,\n",
              " 'wood': 771,\n",
              " 'hadnt': 772,\n",
              " 'gnaw': 773,\n",
              " 'posts': 774,\n",
              " 'birch': 775,\n",
              " 'boughs': 776,\n",
              " 'piled': 777,\n",
              " 'everywhere—': 778,\n",
              " 'isola': 779,\n",
              " 'doro': 780,\n",
              " 'fior': 781,\n",
              " 'di': 782,\n",
              " 'levante': 783,\n",
              " 'doorsill': 784,\n",
              " 'corner': 785,\n",
              " 'piece': 786,\n",
              " 'thoughts': 787,\n",
              " 'palsied': 788,\n",
              " 'misty': 789,\n",
              " 'mid': 790,\n",
              " 'region': 791,\n",
              " 'weir': 792,\n",
              " 'ultimate': 793,\n",
              " 'climes': 794,\n",
              " 'pole': 795,\n",
              " 'leg': 796,\n",
              " 'crutch': 797,\n",
              " 'ridgepole': 798,\n",
              " 'stride': 799,\n",
              " 'broomstick': 800,\n",
              " 'cellarstairs': 801,\n",
              " 'theyll': 802,\n",
              " 'theyve': 803,\n",
              " 'whole': 804,\n",
              " 'thing': 805,\n",
              " 'streams': 806,\n",
              " 'dread': 807,\n",
              " 'burden': 808,\n",
              " 'knows': 809,\n",
              " 'kinder': 810,\n",
              " 'run': 811,\n",
              " 'men': 812,\n",
              " 'wind': 813,\n",
              " 'fraught': 814,\n",
              " 'passing': 815,\n",
              " 'wilds': 816,\n",
              " 'mountains': 817,\n",
              " 'intense': 818,\n",
              " 'short': 819,\n",
              " 'sell': 820,\n",
              " 'meddle': 821,\n",
              " 'fate': 822,\n",
              " 'fight': 823,\n",
              " 'smother': 824,\n",
              " 'orchid': 825,\n",
              " 'calypso': 826,\n",
              " 'blotting': 827,\n",
              " 'utterly': 828,\n",
              " 'assailed': 829,\n",
              " 'monarchs': 830,\n",
              " 'estate': 831,\n",
              " 'therefore': 832,\n",
              " 'across': 833,\n",
              " 'sacred': 834,\n",
              " 'sill': 835,\n",
              " 'killed': 836,\n",
              " 'instead': 837,\n",
              " 'courts': 838,\n",
              " 'still': 839,\n",
              " 'unafraid': 840,\n",
              " 'blow': 841,\n",
              " 'selfclear': 842,\n",
              " 'text': 843,\n",
              " 'bidden': 844,\n",
              " 'ran': 845,\n",
              " 'bedroom': 846,\n",
              " 'each': 847,\n",
              " 'bid': 848,\n",
              " 'any': 849,\n",
              " 'twelvemonth': 850,\n",
              " 'until': 851,\n",
              " 'thatd': 852,\n",
              " 'days': 853,\n",
              " 'thats': 854,\n",
              " 'sit': 855,\n",
              " 'melancholy': 856,\n",
              " 'waters': 857,\n",
              " 'proclaimed': 858,\n",
              " 'neither': 859,\n",
              " 'nor': 860,\n",
              " 'stock': 861,\n",
              " 'village': 862,\n",
              " 'library': 863,\n",
              " 'fever': 864,\n",
              " 'minute': 865,\n",
              " 'torn': 866,\n",
              " 'naiad': 867,\n",
              " 'flood': 868,\n",
              " 'upon': 869,\n",
              " 'shelf': 870,\n",
              " 'tote': 871,\n",
              " 'clearing': 872,\n",
              " 'lived': 873,\n",
              " 'rapid': 874,\n",
              " 'ghastly': 875,\n",
              " 'river': 876,\n",
              " 'making': 877,\n",
              " 'allowance': 878,\n",
              " 'due': 879,\n",
              " 'something': 880,\n",
              " 'throw': 881,\n",
              " 'hoe': 882,\n",
              " 'elfin': 883,\n",
              " 'green': 884,\n",
              " 'grave': 885,\n",
              " 'cellar': 886,\n",
              " 'wont': 887,\n",
              " 'accept': 888,\n",
              " 'substitute': 889,\n",
              " 'arthur': 890,\n",
              " 'amy': 891,\n",
              " 'married': 892,\n",
              " 'ranged': 893,\n",
              " 'pipes': 894,\n",
              " 'smoking': 895,\n",
              " 'jug': 896,\n",
              " 'distinct': 897,\n",
              " 'duplicate': 898,\n",
              " 'horn': 899,\n",
              " 'renewed': 900,\n",
              " 'paint': 901,\n",
              " 'entablatures': 902,\n",
              " 'intertwine': 903,\n",
              " 'yours': 904,\n",
              " 'isnt': 905,\n",
              " 'warmer': 906,\n",
              " 'dian': 907,\n",
              " 'couldnt': 908,\n",
              " 'climb': 909,\n",
              " 'slippery': 910,\n",
              " 'slope': 911,\n",
              " 'reconnoitre': 912,\n",
              " 'according': 913,\n",
              " 'feared': 914,\n",
              " 'risk': 915,\n",
              " 'nearest': 916,\n",
              " 'resembles': 917,\n",
              " 'worship': 918,\n",
              " 'remember': 919,\n",
              " 'ocean': 920,\n",
              " 'throbbing': 921,\n",
              " 'free': 922,\n",
              " 'kneel': 923,\n",
              " 'huh': 924,\n",
              " 'bathtub': 925,\n",
              " 'snow': 926,\n",
              " 'seven': 927,\n",
              " 'years': 928,\n",
              " 'goodlooking': 929,\n",
              " 'picked': 930,\n",
              " 'fresh': 931,\n",
              " 'reeled': 932,\n",
              " 'lurched': 933,\n",
              " 'bobbed': 934,\n",
              " 'checked': 935,\n",
              " 'luminous': 936,\n",
              " 'windows': 937,\n",
              " 'help': 938,\n",
              " 'dig': 939,\n",
              " 'virgin': 940,\n",
              " 'wrapper': 941,\n",
              " 'box': 942,\n",
              " 'heart': 943,\n",
              " 'barn': 944,\n",
              " 'smells': 945,\n",
              " 'wash': 946,\n",
              " 'ploughed': 947,\n",
              " 'sought': 948,\n",
              " 'precipitate': 949,\n",
              " 'pathway': 950,\n",
              " 'rattling': 951,\n",
              " 'shutter': 952,\n",
              " 'kick': 953,\n",
              " 'legs': 954,\n",
              " 'army': 955,\n",
              " 'mule': 956,\n",
              " 'small': 957,\n",
              " 'skiff': 958,\n",
              " 'sake': 959,\n",
              " 'company': 960,\n",
              " 'enshrined': 961,\n",
              " 'growing': 962,\n",
              " 'anyone': 963,\n",
              " 'fingerbone': 964,\n",
              " 'wanted': 965,\n",
              " 'age': 966,\n",
              " 'along': 967,\n",
              " 'shouting': 968,\n",
              " 'helping': 969,\n",
              " 'cruel': 970,\n",
              " 'remembered': 971,\n",
              " 'johns': 972,\n",
              " 'idea': 973,\n",
              " 'thus': 974,\n",
              " 'pacified': 975,\n",
              " 'psyche': 976,\n",
              " 'kissed': 977,\n",
              " 'nighttime': 978,\n",
              " 'theres': 979,\n",
              " 'shes': 980,\n",
              " 'kiting': 981,\n",
              " 'happier': 982,\n",
              " 'tumble': 983,\n",
              " 'stricken': 984,\n",
              " 'past': 985,\n",
              " 'lion': 986,\n",
              " 'very': 987,\n",
              " 'hours': 988,\n",
              " 'breathing': 989,\n",
              " 'low': 990,\n",
              " 'nature': 991,\n",
              " 'country': 992,\n",
              " 'cultures': 993,\n",
              " 'faded': 994,\n",
              " 'ride': 995,\n",
              " 'sproutlands': 996,\n",
              " 'flourish': 997,\n",
              " 'axe': 998,\n",
              " 'street': 999,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(word2idx)"
      ],
      "metadata": {
        "id": "JfxMGNUJN2pq",
        "outputId": "bca1170c-d828-44a1-9523-330ad5bfa481",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2520"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert data into integer format\n",
        "train_text_int = []\n",
        "test_text_int = []\n",
        "\n",
        "for text in train_text:\n",
        "  tokens = text.split()\n",
        "  line_as_int = [word2idx[token] for token in tokens]\n",
        "  train_text_int.append(line_as_int)\n",
        "\n",
        "for text in test_text:\n",
        "  tokens = text.split()\n",
        "  line_as_int = [word2idx.get(token, 0) for token in tokens] # to handle the fact that not all tokens in test test is present in word2idx\n",
        "  test_text_int.append(line_as_int)"
      ],
      "metadata": {
        "id": "cIek_h2fN5-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_text_int[100:105]"
      ],
      "metadata": {
        "id": "UV62_8-sOJ0q",
        "outputId": "f5be63e9-f515-460b-af5d-53f1b5f92558",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[36, 391, 65, 35, 392, 393, 104],\n",
              " [56, 394, 115, 40, 395, 45, 164, 396, 48, 397],\n",
              " [398, 173, 252, 399, 86, 400, 401, 402],\n",
              " [20, 7, 403, 404],\n",
              " [65, 48, 405, 406, 229, 48, 407, 65, 48, 408]]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize A and pi matrices - for both classes\n",
        "V = len(word2idx)\n",
        "\n",
        "A0 = np.ones((V, V))\n",
        "pi0 = np.ones(V)\n",
        "\n",
        "A1 = np.ones((V, V))\n",
        "pi1 = np.ones(V)"
      ],
      "metadata": {
        "id": "FGIy6BdwONJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute counts for A and pi\n",
        "def compute_counts(text_as_int, A, pi):\n",
        "  for tokens in text_as_int:\n",
        "    last_idx = None\n",
        "    for idx in tokens:\n",
        "      if last_idx is None:\n",
        "        # it's the first word in a sentence\n",
        "        pi[idx] += 1\n",
        "      else:\n",
        "        # the last word exists, so count a transition\n",
        "        A[last_idx, idx] += 1\n",
        "\n",
        "      # update last_idx\n",
        "      last_idx = idx\n",
        "\n",
        "compute_counts([t for t, y in zip(train_text_int, y_train) if y == 0], A0, pi0)\n",
        "compute_counts([t for t, y in zip(train_text_int, y_train) if y == 1], A1, pi1)"
      ],
      "metadata": {
        "id": "6fW3n5SnOPKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize A and pi so they are valid probability matrices\n",
        "A0 /= A0.sum(axis=1, keepdims=True)\n",
        "pi0 /= pi0.sum()\n",
        "\n",
        "A1 /= A1.sum(axis=1, keepdims=True)\n",
        "pi1 /= pi1.sum()"
      ],
      "metadata": {
        "id": "zzHL0parORdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# log A and pi since we don't need the actual probs\n",
        "logA0 = np.log(A0)\n",
        "logpi0 = np.log(pi0)\n",
        "\n",
        "logA1 = np.log(A1)\n",
        "logpi1 = np.log(pi1)"
      ],
      "metadata": {
        "id": "UEXr2OMWOacp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute priors\n",
        "count0 = sum(y == 0 for y in y_train)\n",
        "count1 = sum(y == 1 for y in y_train)\n",
        "total = len(y_train)\n",
        "p0 = count0 / total\n",
        "p1 = count1 / total\n",
        "logp0 = np.log(p0)\n",
        "logp1 = np.log(p1)\n",
        "p0, p1"
      ],
      "metadata": {
        "id": "kVsnv4BqOc5B",
        "outputId": "17c1b367-bb7d-4de3-8f2c-584c47f91cfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.32507739938080493, 0.6749226006191951)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build a classifier\n",
        "class Classifier:\n",
        "  def __init__(self, logAs, logpis, logpriors):\n",
        "    self.logAs = logAs\n",
        "    self.logpis = logpis\n",
        "    self.logpriors = logpriors\n",
        "    self.K = len(logpriors) # number of classes\n",
        "\n",
        "  def _compute_log_likelihood(self, input_, class_):\n",
        "    logA = self.logAs[class_]\n",
        "    logpi = self.logpis[class_]\n",
        "\n",
        "    last_idx = None\n",
        "    logprob = 0\n",
        "    for idx in input_:\n",
        "      if last_idx is None:\n",
        "        # it's the first token\n",
        "        logprob += logpi[idx]\n",
        "      else:\n",
        "        logprob += logA[last_idx, idx]\n",
        "\n",
        "      # update last_idx\n",
        "      last_idx = idx\n",
        "    return logprob\n",
        "\n",
        "  def predict(self, inputs):\n",
        "    predictions = np.zeros(len(inputs))\n",
        "    for i, input_ in enumerate(inputs):\n",
        "      posteriors = [self._compute_log_likelihood(input_, c) + self.logpriors[c] \\\n",
        "                    for c in range(self.K)]\n",
        "      pred = np.argmax(posteriors)\n",
        "      predictions[i] = pred\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "UbCMt35NOfFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# each array must be in order since classes are assumed to index these lists\n",
        "clf = Classifier([logA0, logA1], [logpi0, logpi1], [logp0, logp1])"
      ],
      "metadata": {
        "id": "TGf0WrLYOhip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Ptrain = clf.predict(train_text_int)\n",
        "print(f\"Train acc: {np.mean(Ptrain == y_train)}\")"
      ],
      "metadata": {
        "id": "eWwtZnuGOj6i",
        "outputId": "f80a979e-a1bb-4e9d-f0b7-af6983783372",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train acc: 0.9950464396284829\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Ptest = clf.predict(test_text_int)\n",
        "print(f\"Test acc: {np.mean(Ptest == y_test)}\")"
      ],
      "metadata": {
        "id": "a4L8z4bVOl5D",
        "outputId": "493182c4-d7f5-4e54-ab4b-e8b0def004ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test acc: 0.8070500927643784\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "cm_train = confusion_matrix(y_train, Ptrain)\n",
        "cm_train"
      ],
      "metadata": {
        "id": "8WjIIvVvOoQ2",
        "outputId": "4a62ddc4-5690-4e58-ab6c-e1ca4290ce75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 517,    8],\n",
              "       [   0, 1090]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm_test = confusion_matrix(y_test, Ptest)\n",
        "cm_test"
      ],
      "metadata": {
        "id": "wb78Mo1KOqN7",
        "outputId": "4fb7c68d-b094-4ce2-d217-957884dc1ade",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 95,  98],\n",
              "       [  6, 340]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score(y_train, Ptrain), f1_score(y_test, Ptest)"
      ],
      "metadata": {
        "id": "9Af9jk_mOtMI",
        "outputId": "2aae85c7-505a-4f8f-c8b1-c9b70cb4454e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9963436928702011, 0.8673469387755102)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Case Study - Poetry Generator"
      ],
      "metadata": {
        "id": "o0yvqCG2fRqC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import string\n",
        "\n",
        "np.random.seed(1234)"
      ],
      "metadata": {
        "id": "Clq8bc8QfcEg"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial = {} # start of a phrase\n",
        "first_order = {} # second word only\n",
        "second_order = {}"
      ],
      "metadata": {
        "id": "qU7NExF2f5Xp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punctuation(s):\n",
        "  return s.translate(str.maketrans('', '', string.punctuation))"
      ],
      "metadata": {
        "id": "DvrHglmggRgh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download data\n",
        "!wget -nc https://raw.githubusercontent.com/lazyprogrammer/machine_learning_examples/master/hmm_class/robert_frost.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSwM2hIeg9q2",
        "outputId": "dbd8595b-5d39-40de-d470-920344aca43c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-15 10:49:43--  https://raw.githubusercontent.com/lazyprogrammer/machine_learning_examples/master/hmm_class/robert_frost.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 56286 (55K) [text/plain]\n",
            "Saving to: ‘robert_frost.txt’\n",
            "\n",
            "\rrobert_frost.txt      0%[                    ]       0  --.-KB/s               \rrobert_frost.txt    100%[===================>]  54.97K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-06-15 10:49:44 (13.5 MB/s) - ‘robert_frost.txt’ saved [56286/56286]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def add2dict(d, k, v):\n",
        "  if k not in d:\n",
        "    d[k] = []\n",
        "  d[k].append(v)\n",
        "\n",
        "# [cat, cat, dog, dog, dog, dog, mouse, ...]"
      ],
      "metadata": {
        "id": "2oFayTBlhIFO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for line in open('robert_frost.txt'):\n",
        "  tokens = remove_punctuation(line.rstrip().lower()).split()\n",
        "\n",
        "  T = len(tokens)\n",
        "  for i in range(T):\n",
        "    t = tokens[i]\n",
        "    if i == 0:\n",
        "      # measure the distribution of the first word\n",
        "      initial[t] = initial.get(t, 0.) + 1\n",
        "    else:\n",
        "      t_1 = tokens[i-1]\n",
        "      if i == T - 1:\n",
        "        # measure probabiltty of ending the line\n",
        "        add2dict(second_order, (t_1, t), 'END')\n",
        "      if i == 1:\n",
        "        # measure distribution of the second word\n",
        "        # given only first word\n",
        "        add2dict(first_order, t_1, t)\n",
        "      else:\n",
        "        t_2 = tokens[i-2]\n",
        "        add2dict(second_order, (t_2, t_1), t)"
      ],
      "metadata": {
        "id": "Qh5iH85th6aT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize the distributions\n",
        "initial_total = sum(initial.values())\n",
        "for t, c in initial.items():\n",
        "  initial[t] = c / initial_total"
      ],
      "metadata": {
        "id": "5Tn_lS21k_0H"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert [cat, cat, cat, dog, dog, dog, mouse, ...]\n",
        "# into {cat: 0.5, dog: 0.4, mouse: 0.1}\n",
        "\n",
        "def list2pdict(ts):\n",
        "  # turn each list of possibilities into a dictionary of probabilities\n",
        "  d = {}\n",
        "  n = len(ts)\n",
        "  for t in ts:\n",
        "    d[t] = d.get(t, 0.) + 1\n",
        "  for t, c in d.items():\n",
        "    d[t] = c / n\n",
        "  return d"
      ],
      "metadata": {
        "id": "D4VLgMfqk1f8"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for t_1, ts in first_order.items():\n",
        "  # replace list with dictionary of probabilities\n",
        "  first_order[t_1] = list2pdict(ts)"
      ],
      "metadata": {
        "id": "CJ9K9HYNkyi-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k, ts in second_order.items():\n",
        "  second_order[k] = list2pdict(ts)"
      ],
      "metadata": {
        "id": "i8z8MY0Fn7G_"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_word(d):\n",
        "  # print \"d:\", d\n",
        "  p0 = np.random.random()\n",
        "  # print \"p0:\", p0\n",
        "  cumulative = 0\n",
        "  for t, p in d.items():\n",
        "    cumulative += p\n",
        "    if p0 < cumulative:\n",
        "      return t"
      ],
      "metadata": {
        "id": "4MzI5ogJocYl"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate():\n",
        "  for i in range(4): # generate 4 lines\n",
        "    sentence = []\n",
        "    # initial word\n",
        "    w0 = sample_word(initial)\n",
        "    sentence.append(w0)\n",
        "\n",
        "    # sample second word\n",
        "    w1 = sample_word(first_order[w0])\n",
        "    sentence.append(w1)\n",
        "\n",
        "    # second order transitions until END\n",
        "    while True:\n",
        "      w2 = sample_word(second_order[(w0, w1)])\n",
        "      if w2 == 'END':\n",
        "        break\n",
        "      sentence.append(w2)\n",
        "      w0 = w1\n",
        "      w1 = w2\n",
        "    print(' '.join(sentence))"
      ],
      "metadata": {
        "id": "OX9fGLyntZqo"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utS3yWOut9sV",
        "outputId": "2bd9ed3e-0969-4a32-dcab-dac59fc17888"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the origin of all this now too much\n",
            "though what a gentle lot we are\n",
            "however far you must be near the window toward the light\n",
            "up to it and were off to find or force a strait\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}